{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "2142c879",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torchvision import models\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms as T\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "098fad52",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = r'/home/vijay/learn/kaggle/petfinder/petfinder-pawpularity-score/'\n",
    "os.chdir(ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "dd31a2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(path):\n",
    "    with open(path, \"rb\") as img:\n",
    "        img = Image.open(img)\n",
    "        img.load()\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "cc017a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = T.Compose([\n",
    "    T.Resize((64, 64)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "16b86f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PetDataset(Dataset):\n",
    "    def __init__(self, file, train=True):\n",
    "        self.df = pd.read_csv(os.path.join(ROOT, f\"{file}.csv\"))\n",
    "        self.df['file_path'] = self.df['Id'].apply(lambda x: os.path.join(f\"{file}\", x+\".jpg\"))\n",
    "        self.train = train\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        img = read_image(self.df.iloc[idx]['file_path'])\n",
    "        if self.train:\n",
    "            return preprocess(img), torch.tensor(self.df.iloc[idx]['Pawpularity'], dtype=torch.float32)/100\n",
    "        else:\n",
    "            return preprocess(img)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "3ab0a429",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, epoch, criterian, optimizer):\n",
    "    model.train()\n",
    "    for i in range(epoch):\n",
    "        count = 0\n",
    "        for data, label in dataloader:\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            out = model(data)\n",
    "            loss = criterian(out.ravel(), label)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            count += 1\n",
    "\n",
    "            print(f\"Epoch:{i}, Data:{count}, Loss:{torch.mean(loss).item()}\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0ff97963",
   "metadata": {},
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.lin1 = nn.Linear(in_features=16*27*27, out_features=120)\n",
    "        self.lin2 = nn.Linear(in_features=120, out_features=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(-1, 16*27*27)\n",
    "        x = torch.relu(self.lin1(x))\n",
    "        x = self.lin2(x)\n",
    "        print(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "3352f633",
   "metadata": {},
   "outputs": [],
   "source": [
    "def submission(model):\n",
    "    dataset_test = PetDataset(\"test\", train=False)\n",
    "    dataloader = DataLoader(dataset=dataset_test, batch_size=8, shuffle=False)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "            out = model(data)\n",
    "            print(out)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "915f3b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0, Data:1, Loss:1.9740077257156372\n",
      "Epoch:0, Data:2, Loss:2.15999698638916\n",
      "Epoch:0, Data:3, Loss:2.0038576126098633\n",
      "Epoch:0, Data:4, Loss:2.0254125595092773\n",
      "Epoch:0, Data:5, Loss:2.101158618927002\n",
      "Epoch:0, Data:6, Loss:2.0667481422424316\n",
      "Epoch:0, Data:7, Loss:2.1614415645599365\n",
      "Epoch:0, Data:8, Loss:1.993062973022461\n",
      "Epoch:0, Data:9, Loss:1.9085583686828613\n",
      "Epoch:0, Data:10, Loss:2.0212883949279785\n",
      "Epoch:1, Data:1, Loss:2.0609793663024902\n",
      "Epoch:1, Data:2, Loss:2.102393388748169\n",
      "Epoch:1, Data:3, Loss:1.9767366647720337\n",
      "Epoch:1, Data:4, Loss:2.2230677604675293\n",
      "Epoch:1, Data:5, Loss:2.092487335205078\n",
      "Epoch:1, Data:6, Loss:2.0556998252868652\n",
      "Epoch:1, Data:7, Loss:2.1082406044006348\n",
      "Epoch:1, Data:8, Loss:1.9800457954406738\n",
      "Epoch:1, Data:9, Loss:2.0827395915985107\n",
      "Epoch:1, Data:10, Loss:1.9886611700057983\n",
      "Epoch:2, Data:1, Loss:2.0349316596984863\n",
      "Epoch:2, Data:2, Loss:1.9482394456863403\n",
      "Epoch:2, Data:3, Loss:2.0356531143188477\n",
      "Epoch:2, Data:4, Loss:1.9739620685577393\n",
      "Epoch:2, Data:5, Loss:2.0416719913482666\n",
      "Epoch:2, Data:6, Loss:2.0872905254364014\n",
      "Epoch:2, Data:7, Loss:1.936853289604187\n",
      "Epoch:2, Data:8, Loss:2.020695209503174\n",
      "Epoch:2, Data:9, Loss:2.0579590797424316\n",
      "Epoch:2, Data:10, Loss:2.1898033618927\n"
     ]
    }
   ],
   "source": [
    "dataset = PetDataset(\"train\")\n",
    "dataloader = DataLoader(dataset=dataset, batch_size=1000, shuffle=True)\n",
    "criterian = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=1e-3)\n",
    "\n",
    "model = models.alexnet(pretrained=True)\n",
    "model.classifier[6] = nn.Linear(in_features=4096, out_features=1)\n",
    "\n",
    "train(model, 3, criterian, optimizer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
